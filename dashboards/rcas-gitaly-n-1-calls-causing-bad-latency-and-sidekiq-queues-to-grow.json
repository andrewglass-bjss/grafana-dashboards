{"meta":{"type":"db","canSave":false,"canEdit":false,"canAdmin":false,"canStar":true,"slug":"rcas-gitaly-n-1-calls-causing-bad-latency-and-sidekiq-queues-to-grow","url":"/d/rcas-7479/rcas-gitaly-n-1-calls-causing-bad-latency-and-sidekiq-queues-to-grow","expires":"0001-01-01T00:00:00Z","created":"2019-08-08T19:42:09Z","updated":"2020-03-17T08:58:15Z","updatedBy":"ops-contact@gitlab.com","createdBy":"ops-contact@gitlab.com","version":653,"hasAcl":false,"isFolder":false,"folderId":955,"folderTitle":"RCAs","folderUrl":"/dashboards/f/rcas/rcas","provisioned":false,"provisionedExternalId":""},"dashboard":{"__inputs":[],"__requires":[],"annotations":{"list":[{"datasource":"Pagerduty","enable":true,"hide":false,"iconColor":"#F2495C","limit":100,"name":"GitLab Production Pagerduty","serviceId":"PATDFCE","showIn":0,"tags":[],"type":"tags","urgency":"high"},{"datasource":"Pagerduty","enable":true,"hide":false,"iconColor":"#C4162A","limit":100,"name":"GitLab Production SLO","serviceId":"P7Q44DU","showIn":0,"tags":[],"type":"tags","urgency":"high"},{"datasource":"Simple Annotations","enable":true,"hide":false,"iconColor":"#5794F2","limit":100,"name":"Key Events","queries":[{"date":"2019-08-07T23:00:00Z","text":"Group Zero generates large amount of WebHook, ProjectServer activity"},{"date":"2019-08-08T00:30:00Z","text":"First CPU Spikes"},{"date":"2019-08-08T00:30:00Z","text":"CPU usage on file-33,34,35 starts going up"},{"date":"2019-08-08T01:47:00Z","text":"cache_vulnerability_history feature flag enabled"},{"date":"2019-08-08T04:24:00Z","text":"gitaly latency APDEX starts going down, CPU usage on file-33,34,35 reaches 80%"},{"date":"2019-08-08T05:10:00Z","text":"web_hook queue starts growing"},{"date":"2019-08-08T05:29:00Z","text":"gitaly latency APDEX alert in #alerts-general"},{"date":"2019-08-08T06:28:00Z","text":"Incident opened by EOC"},{"date":"2019-08-08T06:31:00Z","text":"#backend and #g_gitaly pinged for support"},{"date":"2019-08-08T06:41:00Z","text":"IMOC pinged via /pd-mgr"},{"date":"2019-08-08T07:21:00Z","text":"status.io post"},{"date":"2019-08-08T08:03:00Z","text":"users librideploy and dann30 blocked by abuse team - but it didn't help"},{"date":"2019-08-08T08:16:00Z","text":"gitaly on file-33 restarted, post receive queue starting to go down a bit, but then rises again"},{"date":"2019-08-08T08:25:00Z","text":"gitaly on file-34 restarted"},{"date":"2019-08-08T08:29:00Z","text":"gitaly on file-35 restarted"},{"date":"2019-08-08T08:10:00Z","text":"cache_vulnerability_history feature flag disabled"},{"date":"2019-08-08T11:08:00Z","text":"starting to deploy hot patch for Gitaly n+1 calls to prod"},{"date":"2019-08-08T11:14:00Z","text":"post_receive queue starting to decline"},{"date":"2019-08-08T11:20:00Z","text":"deployment of hot patch finished"},{"date":"2019-08-08T11:45:00Z","text":"problematic jobs manually killed"},{"date":"2019-08-08T13:16:00Z","text":"hot patch reverted"},{"date":"2019-08-08T14:30:00Z","text":"manually added web_hook to queue groups on the pages sidekiq nodes to accelerate queue processing"},{"date":"2019-08-08T14:55:00Z","text":"queues down to zero"}],"showIn":0,"tags":[],"type":"tags"}]},"description":"Uploaded by https://gitlab.com/gitlab-com/runbooks/-/jobs/474284250 at Tue Mar 17 08:58:15 UTC 2020","editable":false,"gnetId":null,"graphTooltip":1,"hideControls":false,"id":null,"links":[],"panels":[{"content":"The RCA issue for this incident is at https://gitlab.com/gitlab-com/gl-infra/infrastructure/issues/7479.\n\n\"Group Zero\" is a pseudonym for the group who pushed the extremely large tag sets to GitLab.com.\n\n\"Group Zero\" seems to start generating push activity at about 23h00 hours.\n\nThe first sign of a problem was CPU spikes on some Gitaly nodes.\nThis occurred as Gitaly struggled with _O(n^2)_ `FindAllTag` queries,\ngenerated by `PostReceiveWorkers`.\n","datasource":null,"gridPos":{"h":10,"w":12,"x":0,"y":1},"id":2,"mode":"markdown","title":"CPU on Gitaly","type":"text"},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"$PROMETHEUS_DS","decimals":0,"description":"","fill":0,"gridPos":{"h":10,"w":12,"x":12,"y":1},"id":3,"legend":{"alignAsTable":true,"avg":true,"current":true,"hideEmpty":true,"max":true,"min":true,"rightSide":false,"show":true,"total":false,"values":true},"lines":true,"linewidth":1,"links":[],"nullPointMode":"null","percentage":false,"pointradius":5,"points":false,"renderer":"flot","repeat":null,"seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"expr":"clamp_min(clamp_max(avg(instance_cpu:node_cpu_seconds_not_idle:rate1m{type=\"gitaly\", environment=\"gprd\"}) by (fqdn)\n,1),0)\n","format":"time_series","interval":"1m","intervalFactor":3,"legendFormat":"{{ fqdn }}","refId":"A"}],"thresholds":[],"timeFrom":null,"timeShift":null,"title":"Gitaly Node CPU","tooltip":{"shared":true,"sort":2,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"percentunit","label":"CPU","logBase":1,"max":1,"min":0,"show":true},{"format":"short","label":null,"logBase":1,"max":1,"min":0,"show":false}]},{"content":"The `FindAllTags` will return multiple messages for each request made.\nThis is to ensure that each messages is kept reasonably small.\nBy calculating the average message size, we can detect if Gitaly is having\nto deal with very large tag payloads.\n","datasource":null,"gridPos":{"h":10,"w":12,"x":0,"y":11},"id":4,"mode":"markdown","title":"FindAllTags","type":"text"},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"$PROMETHEUS_DS","decimals":0,"description":"","fill":0,"gridPos":{"h":10,"w":12,"x":12,"y":11},"id":5,"legend":{"alignAsTable":true,"avg":true,"current":true,"hideEmpty":true,"max":true,"min":true,"rightSide":false,"show":true,"total":false,"values":true},"lines":true,"linewidth":1,"links":[],"nullPointMode":"null","percentage":false,"pointradius":5,"points":false,"renderer":"flot","repeat":null,"seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"expr":"grpc_server_msg_sent_total{grpc_method=\"FindAllTags\", environment=\"gprd\"}\n/\ngrpc_server_started_total{grpc_method=\"FindAllTags\", environment=\"gprd\"}\n","format":"time_series","interval":"1m","intervalFactor":3,"legendFormat":"{{ fqdn }}","refId":"A"}],"thresholds":[],"timeFrom":null,"timeShift":null,"title":"FindAllTags Response Size","tooltip":{"shared":true,"sort":2,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"short","label":"Average messages per FindAllTags request","logBase":1,"max":null,"min":0,"show":true},{"format":"short","label":null,"logBase":1,"max":1,"min":0,"show":false}]},{"content":"Queue lengths increased for several reasons:\n\n1. \"Group Zero\" created `post_receive` jobs taking several hours, which starved the Sidekiq workers from performing other tasks.\n1. `post_receive` jobs calling `FindAllTags` put additional load on Gitaly servers which slowed other background tasks down\n","datasource":null,"gridPos":{"h":10,"w":12,"x":0,"y":21},"id":6,"mode":"markdown","title":"Queue Length","type":"text"},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"$PROMETHEUS_DS","decimals":0,"description":"","fill":0,"gridPos":{"h":10,"w":12,"x":12,"y":21},"id":7,"legend":{"alignAsTable":true,"avg":true,"current":true,"hideEmpty":true,"max":true,"min":true,"rightSide":false,"show":true,"total":false,"values":true},"lines":true,"linewidth":1,"links":[],"nullPointMode":"null","percentage":false,"pointradius":5,"points":false,"renderer":"flot","repeat":null,"seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"expr":"sidekiq_queue_size{environment=\"gprd\", name=~\"web_hook|project_service|post_receive\", type=\"redis-sidekiq\"} and on(fqdn) (redis_connected_slaves != 0)\n","format":"time_series","interval":"1m","intervalFactor":3,"legendFormat":"{{ name }}","refId":"A"}],"thresholds":[],"timeFrom":null,"timeShift":null,"title":"Queue Length","tooltip":{"shared":true,"sort":2,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"short","label":"Queue Length","logBase":1,"max":null,"min":0,"show":true},{"format":"short","label":null,"logBase":1,"max":1,"min":0,"show":false}]},{"content":"This chart shows the sum total amount of time spent processing jobs in each queue.\nThe `PostReceive` queue timings appear to be tied to the `FindAllTags` issue, but it\nappears that there may still be a pathologic repository causing high processing time.\n","datasource":null,"gridPos":{"h":10,"w":12,"x":0,"y":31},"id":8,"mode":"markdown","title":"Processing Time","type":"text"},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"$PROMETHEUS_DS","decimals":0,"description":"","fill":0,"gridPos":{"h":10,"w":12,"x":12,"y":31},"id":9,"legend":{"alignAsTable":true,"avg":true,"current":true,"hideEmpty":true,"max":true,"min":true,"rightSide":false,"show":true,"total":false,"values":true},"lines":true,"linewidth":1,"links":[],"nullPointMode":"null","percentage":false,"pointradius":5,"points":false,"renderer":"flot","repeat":null,"seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"expr":"sum(rate(sidekiq_jobs_completion_seconds_sum{environment=\"gprd\", queue=~\"web_hook|project_service|post_receive\"}[1m])) by (queue)\n","format":"time_series","interval":"1m","intervalFactor":3,"legendFormat":"{{ queue }}","refId":"A"}],"thresholds":[],"timeFrom":null,"timeShift":null,"title":"Processing Time","tooltip":{"shared":true,"sort":2,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"short","label":"Total Processing Time","logBase":1,"max":null,"min":0,"show":true},{"format":"short","label":null,"logBase":1,"max":1,"min":0,"show":false}]},{"content":"`PostRecieve` latency. Lower is better. As a retrospective item, [we have now added](https://gitlab.com/gitlab-com/runbooks/merge_requests/1318) per-worker latency monitoring.\nthis shows the p80 latency of the `PostReceive` worker. This rose due to Gitaly latency caused by the `FindAllTags` issue and the huge payloads being processes.\n","datasource":null,"gridPos":{"h":10,"w":12,"x":0,"y":41},"id":10,"mode":"markdown","title":"PostReceive Latency","type":"text"},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"$PROMETHEUS_DS","decimals":0,"description":"","fill":0,"gridPos":{"h":10,"w":12,"x":12,"y":41},"id":11,"legend":{"alignAsTable":true,"avg":true,"current":true,"hideEmpty":true,"max":true,"min":true,"rightSide":false,"show":true,"total":false,"values":true},"lines":true,"linewidth":1,"links":[],"nullPointMode":"null","percentage":false,"pointradius":5,"points":false,"renderer":"flot","repeat":null,"seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"expr":"histogram_quantile(0.8, sum(rate(sidekiq_jobs_completion_seconds_bucket{environment=\"gprd\", queue=\"post_receive\"}[$__interval])) by (le, environment, stage, tier, type, queue))\n","format":"time_series","interval":"1m","intervalFactor":3,"legendFormat":"{{ queue }}","refId":"A"}],"thresholds":[],"timeFrom":null,"timeShift":null,"title":"p80 Latency for PostReceive jobs","tooltip":{"shared":true,"sort":2,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"format":"short","label":"PostReceive latency","logBase":1,"max":null,"min":0,"show":true},{"format":"short","label":null,"logBase":1,"max":1,"min":0,"show":false}]}],"refresh":"","rows":[],"schemaVersion":16,"style":"light","tags":["managed","rcas","rca"],"templating":{"list":[{"current":{"text":"Prometheus","value":"Prometheus"},"hide":0,"label":null,"name":"PROMETHEUS_DS","options":[],"query":"prometheus","refresh":1,"regex":"/(.*-gprd|Global|gprd-.*)/","type":"datasource"},{"allValue":null,"current":{"text":"gprd","value":"gprd"},"datasource":"$PROMETHEUS_DS","hide":0,"includeAll":false,"label":null,"multi":false,"name":"environment","options":[],"query":"label_values(gitlab_service_ops:rate, environment)","refresh":1,"regex":"","sort":1,"tagValuesQuery":"","tags":[],"tagsQuery":"","type":"query","useTags":false}]},"time":{"from":"2019-08-07 22:00:00","to":"2019-08-08 18:00:00"},"timepicker":{"refresh_intervals":["5s","10s","30s","1m","5m","15m","30m","1h","2h","1d"],"time_options":["5m","15m","1h","6h","12h","24h","2d","7d","30d"]},"timezone":"utc","title":"rcas: Gitaly n+1 calls causing bad latency and sidekiq queues to grow","uid":"rcas-7479","version":653}}